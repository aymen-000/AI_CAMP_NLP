{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:22:55.416265Z","iopub.execute_input":"2024-12-04T19:22:55.416848Z","iopub.status.idle":"2024-12-04T19:23:05.281138Z","shell.execute_reply.started":"2024-12-04T19:22:55.416794Z","shell.execute_reply":"2024-12-04T19:23:05.280262Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.46.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.26.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**The concept is to transform the sentence (i.e. sequence of text) into a numerical vector and then come up with a linear layer to do the downstream task (classification or regression)**\n![](https://thepythoncode.com/media/articles/finetune-bert-for-semantic-textual-similarity-in-python/image1-min.png)\n\n**In this notebook we will calculate the similarity of different sentences using BERT**\n","metadata":{}},{"cell_type":"markdown","source":"## Import the Libraries","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer, models\nfrom transformers import BertTokenizer\nfrom transformers import get_linear_schedule_with_warmup\nimport torch\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport time\nimport datetime\nimport random\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:05.283012Z","iopub.execute_input":"2024-12-04T19:23:05.283304Z","iopub.status.idle":"2024-12-04T19:23:23.479574Z","shell.execute_reply.started":"2024-12-04T19:23:05.283276Z","shell.execute_reply":"2024-12-04T19:23:23.478876Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Device configuration\n**his code checks if a GPU is available using PyTorch's torch.cuda.is_available() function. If a GPU is detected, it sets the device to GPU (cuda) and prints the GPU details. Otherwise, it defaults to the CPU.**","metadata":{}},{"cell_type":"code","source":"# set configuration \nif torch.cuda.is_available():    \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:23.481016Z","iopub.execute_input":"2024-12-04T19:23:23.481540Z","iopub.status.idle":"2024-12-04T19:23:23.570223Z","shell.execute_reply.started":"2024-12-04T19:23:23.481509Z","shell.execute_reply":"2024-12-04T19:23:23.569299Z"}},"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Load dataser\n\n**The code uses the Hugging Face datasets library to load the \"stsb_multi_mt\" dataset with the \"en\" (English) configuration.**  \n**The STSB Multi-MT dataset is a multilingual version of the Semantic Textual Similarity Benchmark. It consists of sentence pairs with similarity scores ranging from 0 (no similarity) to 5 (identical meaning).**","metadata":{}},{"cell_type":"code","source":"# Load the English version of the STSB dataset\ndataset = load_dataset(\"stsb_multi_mt\", \"en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:25.448373Z","iopub.execute_input":"2024-12-04T19:23:25.448704Z","iopub.status.idle":"2024-12-04T19:23:29.952743Z","shell.execute_reply.started":"2024-12-04T19:23:25.448674Z","shell.execute_reply":"2024-12-04T19:23:29.951849Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a43226b2e24427a5c56833125d3d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/470k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54581f67e59451bb420be2af9836bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/108k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c74c79db0adb4fc986f595aac4b10be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/142k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ce866996614fa3a7a4d89ca9243f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"049a46fd8ee544ed91cd9a81d3b06f42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceb4df250cbf484aae2c073cc751fd19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8eaced350a48b6ba7b1ebddda022c1"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:29.979807Z","iopub.execute_input":"2024-12-04T19:23:29.980074Z","iopub.status.idle":"2024-12-04T19:23:29.986062Z","shell.execute_reply.started":"2024-12-04T19:23:29.980048Z","shell.execute_reply":"2024-12-04T19:23:29.985207Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'similarity_score'],\n        num_rows: 5749\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'similarity_score'],\n        num_rows: 1379\n    })\n    dev: Dataset({\n        features: ['sentence1', 'sentence2', 'similarity_score'],\n        num_rows: 1500\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dataset[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:29.987768Z","iopub.execute_input":"2024-12-04T19:23:29.988087Z","iopub.status.idle":"2024-12-04T19:23:30.001362Z","shell.execute_reply.started":"2024-12-04T19:23:29.988044Z","shell.execute_reply":"2024-12-04T19:23:30.000459Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'A plane is taking off.',\n 'sentence2': 'An air plane is taking off.',\n 'similarity_score': 5.0}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Import BERT Tokenizer and Model\n\n**In this notebook we will use the bert-base-uncased model. To use it we will need to import both the tokenizer and the model: The tokenizer will enable us to transform strings into tensors that can be then sent to the model, which in turn will give us the embeddings.**","metadata":{}},{"cell_type":"code","source":"# load bert from hugging  face \n# You can use larger variants of the model, here we're using the base model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nclass BertForSTS(torch.nn.Module):\n\n    def __init__(self):\n        super(BertForSTS, self).__init__()\n        self.bert = models.Transformer('bert-base-uncased', max_seq_length=128)\n        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n\n    def forward(self, input_data):\n        output = self.sts_bert(input_data)['sentence_embedding']\n        return output\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:30.799128Z","iopub.execute_input":"2024-12-04T19:23:30.799864Z","iopub.status.idle":"2024-12-04T19:23:31.889821Z","shell.execute_reply.started":"2024-12-04T19:23:30.799815Z","shell.execute_reply":"2024-12-04T19:23:31.888869Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaecf574d59d4ba29296996bb25c793a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550e5d24c25c4756a3869ac7392d4f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d5bbaee7ab244299dd8fd950fe518b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39171639c9243598282cbc3e07e420f"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Instantiate the model and move it to GPU\nmodel = BertForSTS()\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:32.874764Z","iopub.execute_input":"2024-12-04T19:23:32.875511Z","iopub.status.idle":"2024-12-04T19:23:35.912190Z","shell.execute_reply.started":"2024-12-04T19:23:32.875479Z","shell.execute_reply":"2024-12-04T19:23:35.911241Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b25da8c0bda4db3b40fee43544f011c"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertForSTS(\n  (bert): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n  (pooling_layer): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n  (sts_bert): SentenceTransformer(\n    (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n    (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n  )\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Preparing the Data\n**In order to provide our model with properly prepared data, we’ll define a custom data loader class named MRPCDataset. A data loader class is necessary to efficiently load and prepare your data for training or inference in a Machine Learning setting. It provides functionality for loading data from a dataset, applying the necessary transformations or preprocessing steps, and batching the data for efficient processing**","metadata":{}},{"cell_type":"code","source":"class STSBDataset(torch.utils.data.Dataset):\n\n    def __init__(self, dataset):\n        # Normalize the similarity scores in the dataset\n        similarity_scores = [i['similarity_score'] for i in dataset]\n        self.normalized_similarity_scores = [i/5.0 for i in similarity_scores]\n        self.first_sentences = [i['sentence1'] for i in dataset]\n        self.second_sentences = [i['sentence2'] for i in dataset]\n        self.concatenated_sentences = [[str(x), str(y)] for x,y in   zip(self.first_sentences, self.second_sentences)]\n\n    def __len__(self):\n        return len(self.concatenated_sentences)\n\n    def get_batch_labels(self, idx):\n        return torch.tensor(self.normalized_similarity_scores[idx])\n\n    def get_batch_texts(self, idx):\n        return tokenizer(self.concatenated_sentences[idx], padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n\n    def __getitem__(self, idx):\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n        return batch_texts, batch_y\n\n\ndef collate_fn(texts):\n    input_ids = texts['input_ids']\n    attention_masks = texts['attention_mask']\n    features = [{'input_ids': input_id, 'attention_mask': attention_mask}\n                for input_id, attention_mask in zip(input_ids, attention_masks)]\n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:36.502336Z","iopub.execute_input":"2024-12-04T19:23:36.502670Z","iopub.status.idle":"2024-12-04T19:23:36.509874Z","shell.execute_reply.started":"2024-12-04T19:23:36.502640Z","shell.execute_reply":"2024-12-04T19:23:36.509044Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Defining the Loss Function\n**Since our objective is to train a model to effectively differentiate between pairs of texts based on their semantic meaning. The desired outcome is for the model to learn to separate dissimilar text pairs by assigning them a large distance or dissimilarity score while keeping similar text pairs close together with a small distance or similarity score.**","metadata":{}},{"cell_type":"code","source":"class CosineSimilarityLoss(torch.nn.Module):\n\n    def __init__(self,  loss_fn=torch.nn.MSELoss(), transform_fn=torch.nn.Identity()):\n        super(CosineSimilarityLoss, self).__init__()\n        self.loss_fn = loss_fn\n        self.transform_fn = transform_fn\n        self.cos_similarity = torch.nn.CosineSimilarity(dim=1)\n\n    def forward(self, inputs, labels):\n        emb_1 = torch.stack([inp[0] for inp in inputs])\n        emb_2 = torch.stack([inp[1] for inp in inputs])\n        outputs = self.transform_fn(self.cos_similarity(emb_1, emb_2))\n        return self.loss_fn(outputs, labels.squeeze())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:37.978459Z","iopub.execute_input":"2024-12-04T19:23:37.978797Z","iopub.status.idle":"2024-12-04T19:23:37.984956Z","shell.execute_reply.started":"2024-12-04T19:23:37.978768Z","shell.execute_reply":"2024-12-04T19:23:37.983880Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Preparing the Training and Validation Data Splits","metadata":{}},{"cell_type":"code","source":"train_ds = STSBDataset(dataset['train'])\nval_ds = STSBDataset(dataset['dev'])\n\n# Create a 90-10 train-validation split.\ntrain_size = len(train_ds)\nval_size = len(val_ds)\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:39.504843Z","iopub.execute_input":"2024-12-04T19:23:39.505188Z","iopub.status.idle":"2024-12-04T19:23:40.061047Z","shell.execute_reply.started":"2024-12-04T19:23:39.505157Z","shell.execute_reply":"2024-12-04T19:23:40.060100Z"}},"outputs":[{"name":"stdout","text":"5,749 training samples\n1,500 validation samples\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"batch_size = 8\n\ntrain_dataloader = DataLoader(\n            train_ds,  # The training samples.\n            num_workers = 4,\n            batch_size = batch_size, # Use this batch size.\n            shuffle=True # Select samples randomly for each batch\n        )\n\nvalidation_dataloader = DataLoader(\n            val_ds,\n            num_workers = 4,\n            batch_size = batch_size # Use the same batch size\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:41.042155Z","iopub.execute_input":"2024-12-04T19:23:41.042472Z","iopub.status.idle":"2024-12-04T19:23:41.047121Z","shell.execute_reply.started":"2024-12-04T19:23:41.042445Z","shell.execute_reply":"2024-12-04T19:23:41.046266Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr = 1e-6)\nepochs = 8\n# Total number of training steps is [number of batches] x [number of epochs].\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:23:42.559674Z","iopub.execute_input":"2024-12-04T19:23:42.560292Z","iopub.status.idle":"2024-12-04T19:23:42.565594Z","shell.execute_reply.started":"2024-12-04T19:23:42.560257Z","shell.execute_reply":"2024-12-04T19:23:42.564679Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train():\n    seed_val = 42\n    random.seed(seed_val)\n    torch.manual_seed(seed_val)\n\n    criterion = CosineSimilarityLoss()\n    criterion = criterion.cuda()  # Move criterion to GPU if using CUDA\n\n    # We'll store a number of quantities such as training and validation loss,\n    # validation accuracy, and timings.\n    training_stats = []\n    total_t0 = time.time()\n\n    for epoch_i in range(0, epochs):\n        t0 = time.time()\n        total_train_loss = 0\n        model.train()  # Set model to training mode\n\n        # For each batch of training data...\n        for train_data, train_label in tqdm(train_dataloader):\n            train_data['input_ids'] = train_data['input_ids'].to(device)\n            train_data['attention_mask'] = train_data['attention_mask'].to(device)\n            train_data = collate_fn(train_data)\n\n            # Clear previous gradients\n            model.zero_grad()\n\n            # Forward pass\n            output = [model(feature) for feature in train_data]\n\n            # Calculate loss (CrossEntropy expects logits and labels as integers)\n            loss = criterion(output, train_label.to(device))\n            total_train_loss += loss.item()\n\n            # Backward pass to calculate gradients\n            loss.backward()\n\n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # Optimizer step\n            optimizer.step()\n            scheduler.step()\n\n        # Calculate the average loss over all of the batches.\n        avg_train_loss = total_train_loss / len(train_dataloader)\n\n        # Measure how long this epoch took.\n        training_time = time.time() - t0\n\n        # Start validation phase\n        model.eval()  # Set model to evaluation mode\n        total_eval_loss = 0\n        nb_eval_steps = 0\n\n        # Disable gradient calculations during evaluation\n        with torch.no_grad():\n            for val_data, val_label in tqdm(validation_dataloader):\n                val_data['input_ids'] = val_data['input_ids'].to(device)\n                val_data['attention_mask'] = val_data['attention_mask'].to(device)\n                val_data = collate_fn(val_data)\n\n\n                # Calculate loss\n                output = [model(feature) for feature in val_data]\n                loss = criterion(output, val_label.to(device))\n                total_eval_loss += loss.item()\n\n                # Calculate accuracy (for classification)\n\n        # Calculate average validation loss and accuracy\n        avg_val_loss = total_eval_loss / len(validation_dataloader)\n\n        # Record all statistics from this epoch.\n        training_stats.append({\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Validation Loss': avg_val_loss,\n            'Training Time': training_time,\n        })\n\n        # Print out the statistics for this epoch\n        print(f\"Epoch {epoch_i+1}/{epochs}\")\n        print(f\"  Training Loss: {avg_train_loss:.4f}\")\n        print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n        print(f\"  Training Time: {training_time:.2f}s\")\n\n    # Return the trained model and the training stats\n    return model, training_stats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:40:31.037560Z","iopub.execute_input":"2024-12-04T19:40:31.037939Z","iopub.status.idle":"2024-12-04T19:40:31.048344Z","shell.execute_reply.started":"2024-12-04T19:40:31.037906Z","shell.execute_reply":"2024-12-04T19:40:31.047450Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"model ,training_stats = train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:40:36.597205Z","iopub.execute_input":"2024-12-04T19:40:36.597548Z","iopub.status.idle":"2024-12-04T20:12:45.769603Z","shell.execute_reply.started":"2024-12-04T19:40:36.597518Z","shell.execute_reply":"2024-12-04T20:12:45.768520Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 719/719 [03:43<00:00,  3.22it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n  Training Loss: 0.0343\n  Validation Loss: 0.0397\n  Training Time: 223.61s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:42<00:00,  3.23it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/8\n  Training Loss: 0.0334\n  Validation Loss: 0.0372\n  Training Time: 222.51s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:42<00:00,  3.23it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/8\n  Training Loss: 0.0305\n  Validation Loss: 0.0354\n  Training Time: 222.61s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:41<00:00,  3.24it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/8\n  Training Loss: 0.0285\n  Validation Loss: 0.0346\n  Training Time: 221.90s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:42<00:00,  3.23it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/8\n  Training Loss: 0.0272\n  Validation Loss: 0.0338\n  Training Time: 222.77s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:42<00:00,  3.23it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/8\n  Training Loss: 0.0265\n  Validation Loss: 0.0336\n  Training Time: 222.82s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:43<00:00,  3.22it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/8\n  Training Loss: 0.0262\n  Validation Loss: 0.0335\n  Training Time: 223.28s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 719/719 [03:43<00:00,  3.22it/s]\n100%|██████████| 188/188 [00:18<00:00, 10.24it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 8/8\n  Training Loss: 0.0258\n  Validation Loss: 0.0335\n  Training Time: 223.04s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## Results ","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame from our training statistics\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'epoch' as the row index\ndf_stats = df_stats.set_index('epoch')\n\n# Display the table\ndf_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:13:17.462571Z","iopub.execute_input":"2024-12-04T20:13:17.463093Z","iopub.status.idle":"2024-12-04T20:13:17.489785Z","shell.execute_reply.started":"2024-12-04T20:13:17.463054Z","shell.execute_reply":"2024-12-04T20:13:17.488899Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       Training Loss  Validation Loss  Training Time\nepoch                                               \n1           0.034256         0.039693     223.606177\n2           0.033385         0.037189     222.512085\n3           0.030503         0.035444     222.613162\n4           0.028469         0.034555     221.903625\n5           0.027189         0.033816     222.772918\n6           0.026522         0.033556     222.815157\n7           0.026193         0.033490     223.281100\n8           0.025836         0.033490     223.037639","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Training Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.034256</td>\n      <td>0.039693</td>\n      <td>223.606177</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.033385</td>\n      <td>0.037189</td>\n      <td>222.512085</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.030503</td>\n      <td>0.035444</td>\n      <td>222.613162</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.028469</td>\n      <td>0.034555</td>\n      <td>221.903625</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.027189</td>\n      <td>0.033816</td>\n      <td>222.772918</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.026522</td>\n      <td>0.033556</td>\n      <td>222.815157</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.026193</td>\n      <td>0.033490</td>\n      <td>223.281100</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.025836</td>\n      <td>0.033490</td>\n      <td>223.037639</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"## Setting the Model for Inference","metadata":{}},{"cell_type":"code","source":"print(dataset[\"test\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:14:08.322236Z","iopub.execute_input":"2024-12-04T20:14:08.322576Z","iopub.status.idle":"2024-12-04T20:14:08.327998Z","shell.execute_reply.started":"2024-12-04T20:14:08.322548Z","shell.execute_reply":"2024-12-04T20:14:08.327049Z"}},"outputs":[{"name":"stdout","text":"{'sentence1': 'A girl is styling her hair.', 'sentence2': 'A girl is brushing her hair.', 'similarity_score': 2.5}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# load the test set\ntest_dataset = dataset[\"test\"]\n# Prepare the data\nfirst_sent = [test_dataset[i]['sentence1'] for i in range(len(test_dataset))]\nsecond_sent = [test_dataset[i]['sentence2'] for i in range(len(test_dataset))]\nfull_text = [[str(x), str(y)] for x,y in zip(first_sent, second_sent)]\n\nmodel.eval()\n\ndef predict_similarity(sentence_pair):\n  test_input = tokenizer(sentence_pair, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\").to(device)\n  test_input['input_ids'] = test_input['input_ids']\n  test_input['attention_mask'] = test_input['attention_mask']\n  del test_input['token_type_ids']\n  output = model(test_input)\n  sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n  return sim ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:14:44.964429Z","iopub.execute_input":"2024-12-04T20:14:44.964786Z","iopub.status.idle":"2024-12-04T20:14:45.112504Z","shell.execute_reply.started":"2024-12-04T20:14:44.964754Z","shell.execute_reply":"2024-12-04T20:14:45.111873Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"example_1 = full_text[1]\nprint(f\"Sentence 1: {first_sent[1]}\")\nprint(f\"Sentence 2: {second_sent[1]}\")\nprint(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:15:42.274654Z","iopub.execute_input":"2024-12-04T20:15:42.275349Z","iopub.status.idle":"2024-12-04T20:15:42.296011Z","shell.execute_reply.started":"2024-12-04T20:15:42.275300Z","shell.execute_reply":"2024-12-04T20:15:42.295141Z"}},"outputs":[{"name":"stdout","text":"Sentence 1: A group of men play soccer on the beach.\nSentence 2: A group of boys are playing soccer on the beach.\nPredicted similarity score: 0.84\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"example_1 = full_text[300]\nprint(f\"Sentence 1: {first_sent[300]}\")\nprint(f\"Sentence 2: {second_sent[300]}\")\nprint(f\"Predicted similarity score: {round(predict_similarity(example_1), 2)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:16:04.891557Z","iopub.execute_input":"2024-12-04T20:16:04.891929Z","iopub.status.idle":"2024-12-04T20:16:04.912996Z","shell.execute_reply.started":"2024-12-04T20:16:04.891895Z","shell.execute_reply":"2024-12-04T20:16:04.912204Z"}},"outputs":[{"name":"stdout","text":"Sentence 1: A red and white bus drives down an England street.\nSentence 2: A red and white England bus drives down the street.\nPredicted similarity score: 0.95\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"PATH = 'bert-sts.pt'\ntorch.save(model.state_dict(), PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T20:16:48.789757Z","iopub.execute_input":"2024-12-04T20:16:48.790676Z","iopub.status.idle":"2024-12-04T20:16:49.427125Z","shell.execute_reply.started":"2024-12-04T20:16:48.790638Z","shell.execute_reply":"2024-12-04T20:16:49.426308Z"}},"outputs":[],"execution_count":52}]}